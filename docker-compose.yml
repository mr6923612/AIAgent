services:
  # ==================== AI Agent Services ====================
  
  # AI Agent MySQL Database
  backend-mysql:
    image: mysql:8.0
    container_name: backend-mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: root123
      MYSQL_DATABASE: aiagent_chat
    ports:
      - "3307:3306"
    volumes:
      - ./data/aiagent/mysql:/var/lib/mysql
    networks:
      - aiagent-net
    profiles:
      - aiagent

  # AI Agent Backend Service
  aiagent-backend:
    build:
      context: ./crewaiBackend
      dockerfile: Dockerfile
    container_name: aiagent-backend
    restart: always
    ports:
      - "8012:8012"
    environment:
      - MYSQL_HOST=backend-mysql
      - MYSQL_PORT=3306
      - MYSQL_USER=root
      - MYSQL_PASSWORD=root123
      - MYSQL_DATABASE=aiagent_chat
      - RAGFLOW_BASE_URL=http://ragflow-server:80
    volumes:
      - ./crewaiBackend/.env:/app/.env:ro
    depends_on:
      - backend-mysql
    networks:
      - aiagent-net
      - ragflow
    profiles:
      - aiagent

  # AI Agent Frontend Service
  aiagent-frontend:
    build:
      context: ./crewaiFrontend
      dockerfile: Dockerfile
    container_name: aiagent-frontend
    restart: always
    ports:
      - "3000:3000"
    depends_on:
      - aiagent-backend
    networks:
      - aiagent-net
    profiles:
      - aiagent

  # Ollama Local LLM Service
  ollama:
    image: ollama/ollama
    container_name: ollama
    restart: always
    ports:
      - "11434:11434"
    volumes:
      - ./data/ollama:/root/.ollama
    networks:
      - aiagent-net
      - ragflow
    entrypoint: >
      /bin/bash -c "
        echo 'Starting Ollama service...' &&
        ollama serve &
        sleep 15 &&
        echo 'Downloading bge-m3 model...' &&
        ollama pull bge-m3 &&
        echo 'bge-m3 model download complete!' &&
        wait
      "

networks:
  aiagent-net:
    driver: bridge
  ragflow:
    external: true
    name: docker_ragflow
